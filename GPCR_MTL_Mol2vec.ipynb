{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b9c4e90",
   "metadata": {},
   "source": [
    "Replace ECFP & Padel discriptor -> Mol2vec \n",
    "for separate protein Agonist & Antagonist using Autogluon training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce999414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from re import search\n",
    "import os, sys\n",
    "from os import walk\n",
    "import traceback\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import FeatureMetadata\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"             # CPU only\n",
    "os.environ[\"RAY_OBJECT_STORE_ALLOW_SLOW_STORAGE\"] = \"1\"\n",
    "\n",
    "def column_del(name_columnD,df_temp_del, column_drop_list):\n",
    "    for i, columndel in enumerate (column_drop_list):\n",
    "        try:\n",
    "            df_temp_del=df_temp_del.drop(columns=[columndel], axis=1)\n",
    "            #print ('Delete column : ', columndel ,'   -   ', name_columnD)\n",
    "        except:     # KeyError\n",
    "            #print ('Cannot find the column name : ', columndel,'   -   ', name_columnD)\n",
    "            print (' ')\n",
    "    return (df_temp_del)\n",
    "\n",
    "def dataset_split_trainvalidtest (dataload, trainfilein):\n",
    "    trainprotein=re.sub('\\.csv','',trainfilein)\n",
    "    traindata_split_filename=trainprotein+'_train.csv'\n",
    "    validdata_split_filename=trainprotein+'_valid.csv'\n",
    "    trainsize=0.8 # 0.85 or 0.7\n",
    "    traindata, validdata = train_test_split(dataload, train_size=trainsize) #random_state=777,\n",
    "    os.chdir(workpath)\n",
    "    traindata.to_csv(traindata_split_filename,index=False,encoding='utf-8')\n",
    "    validdata.to_csv(validdata_split_filename,index=False,encoding='utf-8')\n",
    "    print ('Split dataset : ', trainfilein, ' -> ', traindata_split_filename,' & ', validdata_split_filename)\n",
    "    return (traindata, validdata)\n",
    "\n",
    "def AUTOGLUON_train(workpath,trainfilein,AIlabel_problem_eval,trainname):\n",
    "    starttime1=time.time()\n",
    "    os.chdir(workpath)\n",
    "    AIlabel,problem_type,eval_metric,AgonistAnagonist_label=AIlabel_problem_eval\n",
    "    trainname1=trainname+'_'\n",
    "    trainname2=re.sub('GPCR_to_train','',trainname) # Agonist or Antagonist\n",
    "    dataload=TabularDataset(trainfilein)\n",
    "    dataload.replace([np.inf, -np.inf], np.nan, inplace=True) ###\n",
    "    #dataload=dataload.dropna()                                ###\n",
    "    trainproteinname=re.sub(trainname1,'',trainfilein) \n",
    "    trainproteinname=re.sub(trainname,'',trainproteinname) \n",
    "    trainproteinname=re.sub('\\.csv','',trainproteinname) \n",
    "    ###\n",
    "    dataload=column_del(name_columnD=trainfilein,df_temp_del=dataload, column_drop_list=['Protein_name', 'ChEMBL ID', 'Species','EfficacyValue_percentage','level_0','Unnamed: 0','index','ECFP', 'Smiles', 'padel1d2d','mol2vec'])\n",
    "    ###\n",
    "    shape_x0,shape_y0=dataload.shape\n",
    "    AGtrain=''\n",
    "    if shape_x0 >8:\n",
    "        AGtrain='True'        \n",
    "        traindata,validdata=dataset_split_trainvalidtest(dataload,trainfilein)\n",
    "        all_x,all_y=dataload.shape\n",
    "        shape_x,shape_y =traindata.shape\n",
    "        shape_x2,shape_y2 =validdata.shape\n",
    "        timelimit = 'YES'  # 'No' \n",
    "\n",
    "        #traintimelimit=int(shape_x/2)       #math.log(shape_x/3)*1.5*60) \n",
    "        #if traintimelimit<1*60:\n",
    "        #    traintimelimit=1*60\n",
    "        #    \n",
    "        #if traintimelimit > 7*60*60:  #3.5*60*60:\n",
    "        #    traintimelimit = 7*60*60 #  3.5*60*60  # - for AG-concat or ATG-concat protein # 7 hr for LONG allconcat traintimelimit=60hr\n",
    "\n",
    "        traintimelimit=1.8*60*60 \n",
    "        \n",
    "        timestamp=time.strftime(\"%m%d\",time.localtime(time.time()))\n",
    "        print ('\\n Now training: ',trainproteinname,' , training data size: ', shape_x, shape_y,' , test data size: ',shape_x2, shape_y2 , ' , \\n Train time: ', (traintimelimit/60) ,' mins  at', time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())) ,'\\n\\n\\n')\n",
    "        if timelimit == 'YES':\n",
    "            if traintimelimit>60:\n",
    "                float2time=int(traintimelimit/60)     #\"{:.2f}\".format(traintimelimit/60)\n",
    "                ML_path = 'AutogluonTRAIN'+timestamp+'_'+trainname2+'_'+trainproteinname+'_'+str(float2time)+'min'\n",
    "            else:\n",
    "                float2time=int(traintimelimit)\n",
    "                ML_path = 'AutogluonTRAIN'+timestamp+'_'+trainname2+'_'+trainproteinname+'_'+str(float2time)+'sec'\n",
    "        else:\n",
    "            timestamp=time.strftime(\"%Y%m%d_%H%M\",time.localtime(time.time()))\n",
    "            ML_path = 'AutogluonTRAIN'+timestamp+'_'+trainname2+'_'+trainproteinname+'_nolimit'\n",
    "        \n",
    "        AGtrain=''\n",
    "        AGtrain_time=0\n",
    "        while AGtrain=='' : \n",
    "            try:\n",
    "                predictor = TabularPredictor(label=AIlabel, problem_type=problem_type, eval_metric=eval_metric,path=ML_path, verbosity=3).fit(train_data=traindata, auto_stack=True, time_limit=traintimelimit, excluded_model_types=['KNN'])  \n",
    "                #predictor = TabularPredictor(label=AIlabel, problem_type=problem_type, eval_metric=eval_metric,path=ML_path, verbosity=3).fit(train_data=traindata, auto_stack=True, time_limit=traintimelimit, hyperparameters={ 'NN': {'ag_args_fit': {'num_gpus': 1}}, KNNRapidsModel : {}, LinearRapidsModel : {}, RFRapidsModel : {'n_estimators': 100}, 'XGB': {'ag_args_fit': {'num_gpus': 1}}, 'FASTAI': {'ag_args_fit': {'num_gpus': 1}}}, excluded_model_types=['KNN']) \n",
    "                print('\\n', time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n Trained ', trainproteinname ,(time.time()-starttime1)/60, ' mins ', '\\n\\n' )\n",
    "                AGtrain='True'\n",
    "            except Exception as e:\n",
    "                print('\\n *** Error: ',e,' \\n')\n",
    "                print ('\\n ***  REDO Autogluon train : ',AGtrain_time,' for the file: ', trainfilein)\n",
    "                print('\\n', time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n')\n",
    "                AGtrain_time=AGtrain_time+1\n",
    "                traintimelimit=traintimelimit+1\n",
    "                AGtrain=''\n",
    "            if AGtrain_time > 7:\n",
    "                AGtrain='False'\n",
    "                leaderboard=pd.DataFrame()\n",
    "                predictor=pd.DataFrame()\n",
    "                print ('\\n ***  Fail Autogluon train : ',AGtrain_time,' for the file: ', trainfilein,' -- NG -- ')\n",
    "            \n",
    "        if AGtrain=='True':\n",
    "            try:\n",
    "                leaderboard=predictor.leaderboard(validdata, extra_metrics=['mse','mae','pearsonr','rmse'], silent=True)\n",
    "                leaderboard=leaderboard.sort_values(by=['score_val'],ascending=False)\n",
    "                leaderboard=leaderboard.reset_index(drop=True)\n",
    "                print ('\\n\\n',leaderboard,'\\n Best model: ', predictor.get_model_best())\n",
    "                leaderboardfile=ML_path+'/leaderboard_'+trainproteinname+'_size'+str(shape_x)+'.csv'\n",
    "                os.chdir(workpath)\n",
    "                leaderboard.to_csv(leaderboardfile,index=False,encoding='utf-8')\n",
    "                print('\\n', time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n')\n",
    "            except Exception as e:\n",
    "                print('\\n *** Error: ',e,' \\n')\n",
    "                print (' * CANNOT do evaluations -> skip', trainfilein,'\\n')\n",
    "                AGtrain='False'\n",
    "                leaderboard=pd.DataFrame()\n",
    "                predictor=pd.DataFrame()\n",
    "    else:\n",
    "        AGtrain='False'\n",
    "        ML_path=''\n",
    "        leaderboard=pd.DataFrame()\n",
    "        predictor=pd.DataFrame()\n",
    "        traintimelimit=0\n",
    "        shape_x=int(shape_x0)\n",
    "        shape_x2=0\n",
    "        traintimelimit=0\n",
    "        trainprotein=re.sub(r'.csv','',trainfilein)\n",
    "        rename_trainfilein=trainprotein+'_smalldataset.csv'\n",
    "        cmd='cp '+trainfilein+' '+rename_trainfilein\n",
    "        print ('\\n\\n small dataset -> copy file: ', trainfilein, rename_trainfilein, '\\n  ', cmd)\n",
    "        os.chdir(workpath)\n",
    "        subprocess.run(cmd, shell=True) #, capture_output=True)\n",
    "        print('\\n', time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n')\n",
    "    return(AGtrain,leaderboard,predictor,ML_path,shape_x0,shape_x,shape_x2,traintimelimit)\n",
    "\n",
    "\n",
    "def HUMANTRAINALLconcat(workpath,substr,trainname):\n",
    "    #substr=['GPCR_to_train','_train.csv','_valid.csv','GPCR_to_trainAgonistAntagonist','GPCR_to_trainAgonist','GPCR_to_trainAntagonist']\n",
    "    os.chdir(workpath)\n",
    "    k=0\n",
    "    l=0\n",
    "    alltrainconcat_file=trainname+'_humanalltrainconcat.csv'\n",
    "    filenames = next(walk(workpath), (None, None, []))[2]\n",
    "    concat_file_list=[]\n",
    "    for i, fff in enumerate (filenames):\n",
    "        if re.search('all', fff):\n",
    "            continue\n",
    "        if re.search('_HUMAN_train.csv', fff):\n",
    "            concat_file_list.append(fff)\n",
    "    sorted(concat_file_list)\n",
    "    print ('concat_file_list: ',concat_file_list, len(concat_file_list))\n",
    "    df_train_all=pd.DataFrame()\n",
    "    for k, to_concat_file in enumerate (concat_file_list):\n",
    "        os.chdir(workpath)\n",
    "        to_concat_file_ori=to_concat_file ##re.sub('_train.csv','',to_concat_file) \n",
    "        #to_concat_file_ori=to_concat_file_ori+'.csv'\n",
    "        df_read=pd.read_csv(to_concat_file_ori, low_memory=False) # concat _HUMAN_train.csv files\n",
    "        print ('-------------- concat file: (',l,') ',to_concat_file_ori,len(df_read),' to ', alltrainconcat_file, len(df_train_all))\n",
    "        if l==0:\n",
    "            df_train_all=df_read\n",
    "            l=l+1\n",
    "            df_read_0=df_read\n",
    "            column_labels=df_read_0.columns\n",
    "        else:\n",
    "            try:\n",
    "                df_train_all=pd.concat([df_train_all,df_read], axis=0, ignore_index=True)\n",
    "                #df_read=df_read.reindex(columns=column_labels)\n",
    "                #df_read=df_read.reindex_like(df_read_0)\n",
    "                #df_train_tmp=df_train_all.append([df_read], ignore_index=True)\n",
    "                #df_train_all=df_train_tmp\n",
    "                l=l+1\n",
    "            except:\n",
    "                print ('skip file: ', to_concat_file_ori)\n",
    "\n",
    "    os.chdir(workpath)\n",
    "    print ('Total concat proteins: ', l, '\\n concat_file_list: ',concat_file_list, len(concat_file_list))\n",
    "    df_train_all.to_csv(alltrainconcat_file,index=False,encoding='utf-8')\n",
    "    print ('Columns: ', df_train_all.columns)\n",
    "    return (alltrainconcat_file)\n",
    "\n",
    "\n",
    "def toTRAINfiles(workpath,trainnum,filenames,df_protein_train,substr,train_result_summary_file,AIlabel_problem_eval):\n",
    "    os.chdir(workpath)\n",
    "    #substr=['GPCR_to_train','_train.csv','_valid.csv','GPCR_to_trainAgonistAntagonist','GPCR_to_trainAgonist','GPCR_to_trainAntagonist']\n",
    "    ec50_label,problem_type,eval_metric,AgonistAnagonist_label= AIlabel_problem_eval\n",
    "    print ('To train files: ', filenames, len(filenames))\n",
    "    for i, trainfilein in enumerate (filenames):\n",
    "        os.chdir(workpath)\n",
    "        print (' ------------------------------ ',trainnum, trainfilein ,' ------------------------------ ')\n",
    "        if re.search(substr[0], trainfilein):\n",
    "            if re.search(substr[3], trainfilein):\n",
    "                trainname=substr[3]\n",
    "            elif re.search(substr[4], trainfilein):\n",
    "                trainname=substr[4]\n",
    "            elif re.search(substr[5], trainfilein):\n",
    "                trainname=substr[5]\n",
    "            trainname1=trainname+'_'\n",
    "            trainproteinname=re.sub(trainname1,'',trainfilein)\n",
    "            trainproteinname=re.sub('\\.csv','',trainproteinname)\n",
    "        df_protein_train.at[trainnum,'trainnum']=\"{:.0f}\".format(trainnum)\n",
    "        df_protein_train.at[trainnum,'Name']=trainproteinname\n",
    "        trainname2=re.sub('GPCR_to_train','',trainname)\n",
    "        df_protein_train.at[trainnum,'trainname']=trainname2\n",
    "        df_protein_train.at[trainnum,'Time']=str(time.strftime(\"%Y%m%d_%H%M\",time.localtime(time.time())))\n",
    "\n",
    "        df_protein_train.to_csv(train_result_summary_file,index=False,encoding='utf-8')\n",
    "        print ('\\n Run AutoGluon: (',trainnum,')', trainfilein,' - ' ,trainproteinname)\n",
    "        print('\\n',time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n')\n",
    "\n",
    "        AGtrain,leaderboard,predictor,ML_path,shape_x0,shape_x,shape_x2,traintimelimit=AUTOGLUON_train(workpath,trainfilein,AIlabel_problem_eval,trainname)\n",
    "\n",
    "        if AGtrain=='True':\n",
    "            \n",
    "            try:\n",
    "                print (trainfilein, ' size ',shape_x,'\\n BEST model: ',predictor.get_model_best(),', score: ', \"{:.2f}\".format(leaderboard.at[0,'score_val'] ,' \\n'))\n",
    "                df_protein_train.at[trainnum,'ALL_size']=\"{:.0f}\".format(shape_x0)\n",
    "                df_protein_train.at[trainnum,'TRAIN_size']=\"{:.0f}\".format(shape_x)\n",
    "                df_protein_train.at[trainnum,'TEST_size']=\"{:.0f}\".format(shape_x2)\n",
    "                df_protein_train.at[trainnum,'BEST_model']=predictor.get_model_best()\n",
    "                df_protein_train.at[trainnum,'score_val']=\"{:.5f}\".format(abs(leaderboard.at[0,'score_val']))                \n",
    "                df_protein_train.at[trainnum,'mean_squared_error']=\"{:.5f}\".format(abs(leaderboard.at[0,'mean_squared_error']))\n",
    "                df_protein_train.at[trainnum,'pearsonr']=\"{:.5f}\".format(leaderboard.at[0,'pearsonr'])\n",
    "                df_protein_train.at[trainnum,'mean_absolute_error']=\"{:.5f}\".format(abs(leaderboard.at[0,'mean_absolute_error']))\n",
    "                df_protein_train.at[trainnum,'root_mean_squared_error']=\"{:.5f}\".format(abs(leaderboard.at[0,'root_mean_squared_error']))\n",
    "                df_protein_train.at[trainnum,'score_test']=\"{:.5f}\".format(leaderboard.at[0,'score_test'])\n",
    "                df_protein_train.at[trainnum,'score_val']=\"{:.5f}\".format(leaderboard.at[0,'score_val'])\n",
    "                df_protein_train.at[trainnum,'traintimelimit_mins']=\"{:.5f}\".format(traintimelimit/60)\n",
    "            except:\n",
    "                df_protein_train.at[trainnum,'ALL_size']=\"{:.0f}\".format(shape_x0)\n",
    "                df_protein_train.at[trainnum,'TRAIN_size']=\"{:.0f}\".format(shape_x)\n",
    "                df_protein_train.at[trainnum,'BEST_model']='skip'\n",
    "                \n",
    "                        \n",
    "            #######   sklearn and evaluate test\n",
    "            #print('\\n *************** sklearn and evaluate test ****************** \\n')\n",
    "            #fileevaluation='GPCR_to_trainEXP2_valid.csv' # 'GPCR_to_trainEXP2_train.csv',\n",
    "            \n",
    "            #df_protein_train,trainnum=TRAINevaluateEXPdata(workpath,predictor,ML_path,fileevaluation,AIlabel_problem_eval,df_protein_train,trainnum)\n",
    "            \n",
    "            #######\n",
    "\n",
    "            \n",
    "        else:\n",
    "            print ('\\n skip \\n\\n', trainnum, trainfilein)\n",
    "            df_protein_train.at[trainnum,'ALL_size']=\"{:.0f}\".format(shape_x0)\n",
    "            df_protein_train.at[trainnum,'TRAIN_size']=\"{:.0f}\".format(shape_x)\n",
    "            df_protein_train.at[trainnum,'BEST_model']='skip'\n",
    "        df_protein_train.at[trainnum,'File_Name']=str(trainfilein)\n",
    "        trainnum=trainnum+1\n",
    "        df_protein_train.to_csv(train_result_summary_file,index=False,encoding='utf-8')\n",
    "        print('\\n', time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), ' done training: ', trainnum,trainfilein)\n",
    "\n",
    "    os.chdir(workpath)\n",
    "    df_protein_train.to_csv(train_result_summary_file,index=False,encoding='utf-8')\n",
    "    print ('\\n ********************************* \\n',df_protein_train,'\\n ********************************* \\n')\n",
    "    print('\\n', time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())),  ' done training proteins \\n', filenames, trainnum, '\\n\\n\\n\\n\\n\\n\\n')\n",
    "    return (df_protein_train,trainnum)\n",
    "\n",
    "\n",
    "def TRAINevaluateDATA(workpath,predictor,ML_path,fileevaluation,AG_ATG,AIlabel_problem_eval,df_TRAINevaluate,trainnum):  \n",
    "    os.chdir(workpath)\n",
    "    print ('=== ', fileevaluation, ' ===')\n",
    "    # AIlabel_problem_eval=[ec50_label,problem_type,eval_metric,AgonistAnagonist_label]\n",
    "    AIlabel=AIlabel_problem_eval[0]\n",
    "    AgonistAnagonist_label=AIlabel_problem_eval[3]\n",
    "\n",
    "    \n",
    "    try:\n",
    "        test_data0=TabularDataset(fileevaluation)  #validdata\n",
    "\n",
    "        ML_path_split=re.split('\\/',ML_path)\n",
    "        ML_path_AgonistAntagonist_test=ML_path_split[-1]\n",
    "        \n",
    "        if AG_ATG=='AG':\n",
    "            test_data=test_data0.loc[test_data0[AgonistAnagonist_label]==1]\n",
    "            AgonistAntagonist_test='Agonist'\n",
    "        elif AG_ATG=='ATG':\n",
    "            test_data=test_data0.loc[test_data0[AgonistAnagonist_label]==-1]\n",
    "            AgonistAntagonist_test='Antagonist'\n",
    "        else:\n",
    "            test_data=test_data0.copy()\n",
    "            AgonistAntagonist_test='AgonistAntagonist'\n",
    "\n",
    "\n",
    "        if re.search('HUMAN',ML_path_AgonistAntagonist_test):\n",
    "            species='HUMAN'\n",
    "        elif re.search('HUMNA',ML_path_AgonistAntagonist_test):\n",
    "            species='HUMAN'\n",
    "        elif re.search('human',ML_path_AgonistAntagonist_test):\n",
    "            species='HUMAN'\n",
    "        elif re.search('INTER',ML_path_AgonistAntagonist_test):\n",
    "            species='INTERSPECIES'\n",
    "        elif re.search('all',ML_path_AgonistAntagonist_test):\n",
    "            species='INTERSPECIES'\n",
    "        else:\n",
    "            species='INTERSPECIES_check'\n",
    "            print('*** check ML_path  ***', ML_path_AgonistAntagonist_test,species)\n",
    "\n",
    "\n",
    "        ### \n",
    "        test_data=test_data.dropna() ## copy()  ## clean data for na\n",
    "        test_data=test_data.reset_index(drop=True)\n",
    "\n",
    "        df_TRAINevaluate.at[trainnum,'SPECIES']=species\n",
    "        df_TRAINevaluate.at[trainnum,'AgonistAntagonist_test']=AgonistAntagonist_test\n",
    "        df_TRAINevaluate.at[trainnum,'test_data size']=\"{:.0f}\".format(len(test_data))\n",
    "        \n",
    "        try:\n",
    "            test_evaluate=predictor.evaluate(test_data)\n",
    "            print (' \\n ++++++++++ \\n ', test_evaluate,' \\n ++++++++++ \\n')\n",
    "            df_TRAINevaluate.at[trainnum,'mean_squared_error']=abs(test_evaluate['mean_squared_error'])\n",
    "            df_TRAINevaluate.at[trainnum,'pearsonr']=test_evaluate['pearsonr']\n",
    "            df_TRAINevaluate.at[trainnum,'mean_absolute_error']=abs(test_evaluate['mean_absolute_error'])\n",
    "            df_TRAINevaluate.at[trainnum,'root_mean_squared_error']=abs(test_evaluate['root_mean_squared_error'])\n",
    "            df_TRAINevaluate.at[trainnum,'r2']=\"{:.3f}\".format(abs(test_evaluate['r2']))\n",
    "            df_TRAINevaluate.at[trainnum,'median_absolute_error']=abs(test_evaluate['median_absolute_error'])\n",
    "        except:\n",
    "            print ('No test evaluate')\n",
    "    except:\n",
    "        print ('*** wrong data ***')\n",
    "    return (df_TRAINevaluate,trainnum)\n",
    "\n",
    "\n",
    "\n",
    "def proteinfiles_evaluation_test(workpath,predictor,ML_path,m,proteinpath,proteinfiles,evaluation_type,AG_ATG,AIlabel_problem_eval,df_TRAINevaluate,trainnum,outputfile,index_vectors_len):\n",
    "    starttime1=time.time()\n",
    "    peotein_index_len,padel_index_len,ECFP_index_len=index_vectors_len\n",
    "    for i,ppp_evaluate in enumerate(proteinfiles):\n",
    "        print ('\\n\\n ----------- \\n',m, ML_path,'\\n', i, ppp_evaluate, '\\n ----------- ')\n",
    "        fileevaluation=proteinpath+'/'+ppp_evaluate\n",
    "        df_TRAINevaluate.at[trainnum,'ML_fullpath']=ML_path\n",
    "        df_TRAINevaluate.at[trainnum,'peotein_index']=\"{:.0f}\".format(peotein_index_len)\n",
    "        df_TRAINevaluate.at[trainnum,'padel_index']=\"{:.0f}\".format(padel_index_len)\n",
    "        df_TRAINevaluate.at[trainnum,'ECFP_index']=\"{:.0f}\".format(ECFP_index_len)\n",
    "        df_TRAINevaluate.at[trainnum,'file_evaluate']=ppp_evaluate\n",
    "        proteinname=re.sub('GPCR_to_trainAgonistAntagonist_','',ppp_evaluate)\n",
    "        proteinname=re.sub('GPCR_to_trainAgonist_','',proteinname)\n",
    "        proteinname=re.sub('GPCR_to_trainAntagonist_','',proteinname)\n",
    "        proteinname=re.sub('GPCR_to_test_','',proteinname)\n",
    "        proteinname=re.sub('_valid.csv','',proteinname)\n",
    "        proteinname=re.sub('_train.csv','',proteinname)\n",
    "        proteinname=re.sub('_smalldataset.csv','',proteinname)\n",
    "        df_TRAINevaluate.at[trainnum,'Name']=proteinname\n",
    "        df_TRAINevaluate.at[trainnum,'evaluate']=evaluation_type\n",
    "        df_TRAINevaluate.at[trainnum,'AG_ATG']=AG_ATG\n",
    "        df_TRAINevaluate,trainnum=TRAINevaluateDATA(workpath,predictor,ML_path,fileevaluation,AG_ATG,AIlabel_problem_eval,df_TRAINevaluate,trainnum)\n",
    "        trainnum=trainnum+1\n",
    "        os.chdir(workpath)\n",
    "        df_TRAINevaluate.to_csv(outputfile,index=False,encoding='utf-8')\n",
    "    print(time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n sub-total = ', (time.time()-starttime1)/3600, ' hrs \\n +++++++++++++ \\n'  )\n",
    "    return(df_TRAINevaluate,trainnum)\n",
    "\n",
    "homepath=str(os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c9cc57",
   "metadata": {},
   "source": [
    "######################################## Main ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564cb683",
   "metadata": {},
   "outputs": [],
   "source": [
    "workpath=homepath+'/GPCR_to_test_Mol2Vec'\n",
    "\n",
    "\n",
    "timestamp=time.strftime(\"%Y%m%d%H%M\",time.localtime(time.time()))\n",
    "print(time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())))\n",
    "starttime=time.time()\n",
    "\n",
    "ec50_label='ActivityValue_log_EC50'\n",
    "AgonistAnagonist_label='AgonistP1AnagonistN1_label'\n",
    "problem_type ='regression'  \n",
    "eval_metric='mean_squared_error'\n",
    "\n",
    "AIlabel_problem_eval=[ec50_label,problem_type,eval_metric,AgonistAnagonist_label]\n",
    "substr=['GPCR_to_train','_train.csv','_valid.csv','GPCR_to_trainAgonistAntagonist','GPCR_to_trainAgonist','GPCR_to_trainAntagonist']\n",
    "\n",
    "train_result_summary_file='protein_train_leaderboard_evaluate_sklearn_'+str(timestamp)+'.csv'\n",
    "\n",
    "\n",
    "trainname=substr[3]\n",
    "os.chdir(workpath)\n",
    "\n",
    "pwd_path=str(os.getcwd())\n",
    "print ('Now path = ', pwd_path)\n",
    "\n",
    "df_protein_train=pd.DataFrame()\n",
    "\n",
    "trainnum=0\n",
    "\n",
    "########################################\n",
    "\n",
    "filenames = ['GPCR_to_trainAgonistAntagonist_humanalltrainconcat_selefeatureTOP200.csv']\n",
    "df_protein_train,trainnum = toTRAINfiles (workpath,trainnum,filenames,df_protein_train,substr,train_result_summary_file,AIlabel_problem_eval)\n",
    "\n",
    "\n",
    "os.chdir(workpath)\n",
    "df_protein_train.to_csv(train_result_summary_file,index=False,encoding='utf-8')\n",
    "\n",
    "##########################################\n",
    "\n",
    "if (time.time()-starttime)/3600 > 1 :\n",
    "    print('\\n',time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n Total = ', (time.time()-starttime)/3600, ' hrs \\n' )\n",
    "elif (time.time()-starttime)/60 > 1 :\n",
    "    print('\\n',time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n Total = ', (time.time()-starttime)/60, ' mins \\n' )\n",
    "else:\n",
    "    print('\\n',time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n Total = ', (time.time()-starttime), ' secs \\n' )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
