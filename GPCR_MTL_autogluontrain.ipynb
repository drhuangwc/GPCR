{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656c6a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the cell first for all setup\n",
    "\n",
    "import re\n",
    "from re import search\n",
    "import os, sys\n",
    "from os import walk\n",
    "import traceback\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import FeatureMetadata\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"             # CPU only\n",
    "os.environ[\"RAY_OBJECT_STORE_ALLOW_SLOW_STORAGE\"] = \"1\"\n",
    "\n",
    "def column_del(name_columnD,df_temp_del, column_drop_list):\n",
    "    for i, columndel in enumerate (column_drop_list):\n",
    "        try:\n",
    "            df_temp_del=df_temp_del.drop(columns=[columndel], axis=1)\n",
    "        except:     # KeyError\n",
    "            print (' ')\n",
    "    return (df_temp_del)\n",
    "\n",
    "def dataset_split_trainvalidtest (dataload, trainfilein):\n",
    "    trainprotein=re.sub('\\.csv','',trainfilein)\n",
    "    traindata_split_filename=trainprotein+'_train.csv'\n",
    "    validdata_split_filename=trainprotein+'_valid.csv'\n",
    "    trainsize=0.8 # 0.85 or 0.7\n",
    "    traindata, validdata = train_test_split(dataload, train_size=trainsize) #random_state=777,\n",
    "    os.chdir(workpath)\n",
    "    traindata.to_csv(traindata_split_filename,index=False,encoding='utf-8')\n",
    "    validdata.to_csv(validdata_split_filename,index=False,encoding='utf-8')\n",
    "    print ('Split dataset : ', trainfilein, ' -> ', traindata_split_filename,' & ', validdata_split_filename)\n",
    "    return (traindata, validdata)\n",
    "\n",
    "def AUTOGLUON_train(workpath,trainfilein,AIlabel_problem_eval,trainname):\n",
    "    starttime1=time.time()\n",
    "    os.chdir(workpath)\n",
    "    AIlabel,problem_type,eval_metric,AgonistAnagonist_label=AIlabel_problem_eval\n",
    "    trainname1=trainname+'_'\n",
    "    trainname2=re.sub('GPCR_to_train','',trainname) # Agonist or Antagonist\n",
    "    dataload=TabularDataset(trainfilein)\n",
    "    dataload.replace([np.inf, -np.inf], np.nan, inplace=True) ###\n",
    "    trainproteinname=re.sub(trainname1,'',trainfilein) \n",
    "    trainproteinname=re.sub(trainname,'',trainproteinname) \n",
    "    trainproteinname=re.sub('\\.csv','',trainproteinname) \n",
    "    dataload=column_del(name_columnD=trainfilein,df_temp_del=dataload, column_drop_list=['Protein_name','ChEMBL ID','Species','EfficacyValue_percentage','level_0', 'index'])\n",
    "    shape_x0,shape_y0=dataload.shape\n",
    "    AGtrain=''\n",
    "    if shape_x0 >8:\n",
    "        AGtrain='True'        \n",
    "        traindata,validdata=dataset_split_trainvalidtest(dataload,trainfilein)\n",
    "        all_x,all_y=dataload.shape\n",
    "        shape_x,shape_y =traindata.shape\n",
    "        shape_x2,shape_y2 =validdata.shape\n",
    "        timelimit = 'YES'  # 'No' \n",
    "\n",
    "        traintimelimit=int(shape_x/2)     \n",
    "        if traintimelimit > 3.5*60*60:\n",
    "            if re.search('trainAgonistAntagonist',trainfilein):\n",
    "                traintimelimit=7*60*60 #for LONG allconcat traintimelimit=60hr\n",
    "            else:\n",
    "                traintimelimit = 3.5*60*60  # - for AG-concat or ATG-concat protein\n",
    "\n",
    "        timestamp=time.strftime(\"%m%d\",time.localtime(time.time()))\n",
    "        print ('\\n Now training: ',trainproteinname,' , training data size: ', shape_x, shape_y,' , test data size: ',shape_x2, shape_y2 , ' , \\n Train time: ', (traintimelimit/60) ,' mins  at', time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())) ,'\\n\\n\\n')\n",
    "        if timelimit == 'YES':\n",
    "            if traintimelimit>60:\n",
    "                float2time=int(traintimelimit/60)    \n",
    "                ML_path = 'AutogluonTRAIN'+timestamp+'_'+trainname2+'_'+trainproteinname+'_'+str(float2time)+'min'\n",
    "            else:\n",
    "                float2time=int(traintimelimit)\n",
    "                ML_path = 'AutogluonTRAIN'+timestamp+'_'+trainname2+'_'+trainproteinname+'_'+str(float2time)+'sec'\n",
    "        else:\n",
    "            timestamp=time.strftime(\"%Y%m%d_%H%M\",time.localtime(time.time()))\n",
    "            ML_path = 'AutogluonTRAIN'+timestamp+'_'+trainname2+'_'+trainproteinname+'_nolimit'\n",
    "        \n",
    "        AGtrain=''\n",
    "        AGtrain_time=0\n",
    "        while AGtrain=='' : \n",
    "            try:\n",
    "                predictor = TabularPredictor(label=AIlabel, problem_type=problem_type, eval_metric=eval_metric,path=ML_path, verbosity=3).fit(train_data=traindata, auto_stack=True, time_limit=traintimelimit, excluded_model_types=['KNN'])  \n",
    "                print('\\n', time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n Trained ', trainproteinname ,(time.time()-starttime1)/60, ' mins ', '\\n\\n' )\n",
    "                AGtrain='True'\n",
    "            except Exception as e:\n",
    "                print('\\n *** Error: ',e,' \\n')\n",
    "                print ('\\n ***  REDO Autogluon train : ',AGtrain_time,' for the file: ', trainfilein)\n",
    "                print('\\n', time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n')\n",
    "                AGtrain_time=AGtrain_time+1\n",
    "                traintimelimit=traintimelimit+1\n",
    "                AGtrain=''\n",
    "            if AGtrain_time > 7:\n",
    "                AGtrain='False'\n",
    "                leaderboard=pd.DataFrame()\n",
    "                predictor=pd.DataFrame()\n",
    "                print ('\\n ***  Fail Autogluon train : ',AGtrain_time,' for the file: ', trainfilein,' -- NG -- ')\n",
    "            \n",
    "        if AGtrain=='True':\n",
    "            try:\n",
    "                leaderboard=predictor.leaderboard(validdata, extra_metrics=['mse','mae','pearsonr','rmse'], silent=True)\n",
    "                leaderboard=leaderboard.sort_values(by=['score_val'],ascending=False)\n",
    "                leaderboard=leaderboard.reset_index(drop=True)\n",
    "                print ('\\n\\n',leaderboard,'\\n Best model: ', predictor.get_model_best())\n",
    "                leaderboardfile=ML_path+'/leaderboard_'+trainproteinname+'_size'+str(shape_x)+'.csv'\n",
    "                os.chdir(workpath)\n",
    "                leaderboard.to_csv(leaderboardfile,index=False,encoding='utf-8')\n",
    "                print('\\n', time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n')\n",
    "            except Exception as e:\n",
    "                print('\\n *** Error: ',e,' \\n')\n",
    "                print (' * CANNOT do evaluations -> skip', trainfilein,'\\n')\n",
    "                AGtrain='False'\n",
    "                leaderboard=pd.DataFrame()\n",
    "                predictor=pd.DataFrame()\n",
    "    else:\n",
    "        AGtrain='False'\n",
    "        ML_path=''\n",
    "        leaderboard=pd.DataFrame()\n",
    "        predictor=pd.DataFrame()\n",
    "        traintimelimit=0\n",
    "        shape_x=int(shape_x0)\n",
    "        shape_x2=0\n",
    "        traintimelimit=0\n",
    "        trainprotein=re.sub(r'.csv','',trainfilein)\n",
    "        rename_trainfilein=trainprotein+'_smalldataset.csv'\n",
    "        cmd='cp '+trainfilein+' '+rename_trainfilein\n",
    "        print ('\\n\\n small dataset -> copy file: ', trainfilein, rename_trainfilein, '\\n  ', cmd)\n",
    "        os.chdir(workpath)\n",
    "        subprocess.run(cmd, shell=True) #, capture_output=True)\n",
    "        print('\\n', time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n')\n",
    "    return(AGtrain,leaderboard,predictor,ML_path,shape_x0,shape_x,shape_x2,traintimelimit)\n",
    "\n",
    "\n",
    "def HUMANTRAINALLconcat(workpath,substr,trainname):\n",
    "    os.chdir(workpath)\n",
    "    k=0\n",
    "    l=0\n",
    "    alltrainconcat_file=trainname+'_humanalltrainconcat.csv'\n",
    "    filenames = next(walk(workpath), (None, None, []))[2]\n",
    "    concat_file_list=[]\n",
    "    for i, fff in enumerate (filenames):\n",
    "        if re.search('all', fff):\n",
    "            continue\n",
    "        if re.search('_HUMAN_train.csv', fff):\n",
    "            concat_file_list.append(fff)\n",
    "    sorted(concat_file_list)\n",
    "    print ('concat_file_list: ',concat_file_list, len(concat_file_list))\n",
    "    df_train_all=pd.DataFrame()\n",
    "    for k, to_concat_file in enumerate (concat_file_list):\n",
    "        os.chdir(workpath)\n",
    "        to_concat_file_ori=to_concat_file \n",
    "        df_read=pd.read_csv(to_concat_file_ori, low_memory=False) \n",
    "        print ('-------------- concat file: (',l,') ',to_concat_file_ori,len(df_read),' to ', alltrainconcat_file, len(df_train_all))\n",
    "        if l==0:\n",
    "            df_train_all=df_read\n",
    "            l=l+1\n",
    "            df_read_0=df_read\n",
    "            column_labels=df_read_0.columns\n",
    "        else:\n",
    "            try:\n",
    "                df_train_all=pd.concat([df_train_all,df_read], axis=0, ignore_index=True)\n",
    "                l=l+1\n",
    "            except:\n",
    "                print ('skip file: ', to_concat_file_ori)\n",
    "\n",
    "    os.chdir(workpath)\n",
    "    print ('Total concat proteins: ', l, '\\n concat_file_list: ',concat_file_list, len(concat_file_list))\n",
    "    df_train_all.to_csv(alltrainconcat_file,index=False,encoding='utf-8')\n",
    "    print ('Columns: ', df_train_all.columns)\n",
    "    return (alltrainconcat_file)\n",
    "\n",
    "def toTRAINfiles(workpath,trainnum,filenames,df_protein_train,substr,train_result_summary_file,AIlabel_problem_eval):\n",
    "    os.chdir(workpath)\n",
    "    ec50_label,problem_type,eval_metric,AgonistAnagonist_label= AIlabel_problem_eval\n",
    "    print ('To train files: ', filenames, len(filenames))\n",
    "    for i, trainfilein in enumerate (filenames):\n",
    "        os.chdir(workpath)\n",
    "        print (' ------------------------------ ',trainnum, trainfilein ,' ------------------------------ ')\n",
    "        if re.search(substr[0], trainfilein):\n",
    "            if re.search(substr[3], trainfilein):\n",
    "                trainname=substr[3]\n",
    "            elif re.search(substr[4], trainfilein):\n",
    "                trainname=substr[4]\n",
    "            elif re.search(substr[5], trainfilein):\n",
    "                trainname=substr[5]\n",
    "            trainname1=trainname+'_'\n",
    "            trainproteinname=re.sub(trainname1,'',trainfilein)\n",
    "            trainproteinname=re.sub('\\.csv','',trainproteinname)\n",
    "        df_protein_train.at[trainnum,'trainnum']=\"{:.0f}\".format(trainnum)\n",
    "        df_protein_train.at[trainnum,'Name']=trainproteinname\n",
    "        trainname2=re.sub('GPCR_to_train','',trainname)\n",
    "        df_protein_train.at[trainnum,'trainname']=trainname2\n",
    "        df_protein_train.at[trainnum,'Time']=str(time.strftime(\"%Y%m%d_%H%M\",time.localtime(time.time())))\n",
    "\n",
    "        df_protein_train.to_csv(train_result_summary_file,index=False,encoding='utf-8')\n",
    "        print ('\\n Run AutoGluon: (',trainnum,')', trainfilein,' - ' ,trainproteinname)\n",
    "        print('\\n',time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n')\n",
    "\n",
    "        AGtrain,leaderboard,predictor,ML_path,shape_x0,shape_x,shape_x2,traintimelimit=AUTOGLUON_train(workpath,trainfilein,AIlabel_problem_eval,trainname)\n",
    "\n",
    "        if AGtrain=='True':\n",
    "            \n",
    "            try:\n",
    "                print (trainfilein, ' size ',shape_x,'\\n BEST model: ',predictor.get_model_best(),', score: ', \"{:.2f}\".format(leaderboard.at[0,'score_val'] ,' \\n'))\n",
    "                df_protein_train.at[trainnum,'ALL_size']=\"{:.0f}\".format(shape_x0)\n",
    "                df_protein_train.at[trainnum,'TRAIN_size']=\"{:.0f}\".format(shape_x)\n",
    "                df_protein_train.at[trainnum,'TEST_size']=\"{:.0f}\".format(shape_x2)\n",
    "                df_protein_train.at[trainnum,'BEST_model']=predictor.get_model_best()\n",
    "                df_protein_train.at[trainnum,'score_val']=\"{:.5f}\".format(abs(leaderboard.at[0,'score_val']))                \n",
    "                df_protein_train.at[trainnum,'mean_squared_error']=\"{:.5f}\".format(abs(leaderboard.at[0,'mean_squared_error']))\n",
    "                df_protein_train.at[trainnum,'pearsonr']=\"{:.5f}\".format(leaderboard.at[0,'pearsonr'])\n",
    "                df_protein_train.at[trainnum,'mean_absolute_error']=\"{:.5f}\".format(abs(leaderboard.at[0,'mean_absolute_error']))\n",
    "                df_protein_train.at[trainnum,'root_mean_squared_error']=\"{:.5f}\".format(abs(leaderboard.at[0,'root_mean_squared_error']))\n",
    "                df_protein_train.at[trainnum,'score_test']=\"{:.5f}\".format(leaderboard.at[0,'score_test'])\n",
    "                df_protein_train.at[trainnum,'score_val']=\"{:.5f}\".format(leaderboard.at[0,'score_val'])\n",
    "                df_protein_train.at[trainnum,'traintimelimit_mins']=\"{:.5f}\".format(traintimelimit/60)\n",
    "            except:\n",
    "                df_protein_train.at[trainnum,'ALL_size']=\"{:.0f}\".format(shape_x0)\n",
    "                df_protein_train.at[trainnum,'TRAIN_size']=\"{:.0f}\".format(shape_x)\n",
    "                df_protein_train.at[trainnum,'BEST_model']='skip'\n",
    "                \n",
    "        else:\n",
    "            print ('\\n skip \\n\\n', trainnum, trainfilein)\n",
    "            df_protein_train.at[trainnum,'ALL_size']=\"{:.0f}\".format(shape_x0)\n",
    "            df_protein_train.at[trainnum,'TRAIN_size']=\"{:.0f}\".format(shape_x)\n",
    "            df_protein_train.at[trainnum,'BEST_model']='skip'\n",
    "        df_protein_train.at[trainnum,'File_Name']=str(trainfilein)\n",
    "        trainnum=trainnum+1\n",
    "        df_protein_train.to_csv(train_result_summary_file,index=False,encoding='utf-8')\n",
    "        print('\\n', time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), ' done training: ', trainnum,trainfilein)\n",
    "\n",
    "    os.chdir(workpath)\n",
    "    df_protein_train.to_csv(train_result_summary_file,index=False,encoding='utf-8')\n",
    "    print ('\\n ********************************* \\n',df_protein_train,'\\n ********************************* \\n')\n",
    "    print('\\n', time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())),  ' done training proteins \\n', filenames, trainnum, '\\n\\n\\n\\n\\n\\n\\n')\n",
    "    return (df_protein_train,trainnum)\n",
    "\n",
    "\n",
    "\n",
    "ec50_label='ActivityValue_log_EC50'\n",
    "AgonistAnagonist_label='AgonistP1AnagonistN1_label'\n",
    "problem_type ='regression'  \n",
    "eval_metric='mean_squared_error'\n",
    "\n",
    "AIlabel_problem_eval=[ec50_label,problem_type,eval_metric,AgonistAnagonist_label]\n",
    "substr=['GPCR_to_train','_train.csv','_valid.csv','GPCR_to_trainAgonistAntagonist','GPCR_to_trainAgonist','GPCR_to_trainAntagonist']\n",
    "\n",
    "homepath=str(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f35416d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### CODE: Main\n",
    "##### for separate protein Agonist using Autogluon training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01ef96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate protein Agonist training\n",
    "\n",
    "timestamp=time.strftime(\"%Y%m%d%H%M\",time.localtime(time.time()))\n",
    "starttime=time.time()\n",
    "\n",
    "train_result_summary_file='protein_train_leaderboard_evaluate_sklearn_'+str(timestamp)+'.csv'\n",
    "\n",
    "workpath=homepath+'/Human_AgonistAntagonist/GPCR_separatePROTEIN/Agonist'\n",
    "\n",
    "trainname=substr[4]\n",
    "os.chdir(workpath)\n",
    "\n",
    "df_protein_train=pd.DataFrame()\n",
    "trainnum=0 \n",
    "################################### to all train separate ##########################################\n",
    "filenames=[]\n",
    "pp2skip=[]\n",
    "trainname1=trainname+'_'\n",
    "folderfiles=(sorted(next(walk(workpath))[2], reverse = True))\n",
    "for i, file in enumerate (folderfiles):\n",
    "    ppname=re.sub(trainname1,'',file)\n",
    "    if re.search('_train.csv', file):\n",
    "        ppname=re.sub(substr[1],'',ppname)\n",
    "        pp2skip.append(ppname)\n",
    "        continue\n",
    "    if re.search('_valid.csv', file):\n",
    "        ppname=re.sub(substr[2],'',ppname)\n",
    "        pp2skip.append(ppname)\n",
    "        continue\n",
    "    if re.search('_smalldataset.csv', file):\n",
    "        ppname=re.sub('_smalldataset.csv','',ppname)\n",
    "        pp2skip.append(ppname)\n",
    "        continue\n",
    "    if re.search(trainname, file):\n",
    "        filenames.append(file)\n",
    "        \n",
    "filenames=sorted(filenames)\n",
    "print (filenames,len(filenames))\n",
    "df_protein_train,trainnum = toTRAINfiles (workpath,trainnum,filenames,df_protein_train,substr,train_result_summary_file,AIlabel_problem_eval)\n",
    "\n",
    "print(time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n Total = ', (time.time()-starttime)/3600, ' hrs \\n' )\n",
    "\n",
    "\n",
    "os.chdir(workpath)\n",
    "df_protein_train.to_csv(train_result_summary_file,index=False,encoding='utf-8')\n",
    "\n",
    "\n",
    "\n",
    "print('\\n', time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '  \\n done all training separate  proteins \\n')\n",
    "\n",
    "\n",
    "###################################  alltrain concat ##########################################\n",
    "timestamp=time.strftime(\"%m%d\",time.localtime(time.time()))\n",
    "starttime=time.time()\n",
    "\n",
    "alltrainconcat_file = HUMANTRAINALLconcat(workpath,substr,trainname)\n",
    "\n",
    "filenames = [alltrainconcat_file]\n",
    "df_protein_train,trainnum = toTRAINfiles (workpath,trainnum,filenames,df_protein_train,substr,train_result_summary_file,AIlabel_problem_eval)\n",
    "\n",
    "\n",
    "os.chdir(workpath)\n",
    "df_protein_train.to_csv(train_result_summary_file,index=False,encoding='utf-8')\n",
    "\n",
    "\n",
    "##########################################\n",
    "\n",
    "if (time.time()-starttime)/3600 > 1 :\n",
    "    print(time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n Total = ', (time.time()-starttime)/3600, ' hrs \\n' )\n",
    "else:\n",
    "    print(time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n Total = ', (time.time()-starttime)/60, ' mins \\n' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae0c2f2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### CODE: Main\n",
    "##### for separate protein Antagonist using Autogluon training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b0be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate protein Antagonist training\n",
    "\n",
    "timestamp=time.strftime(\"%Y%m%d%H%M\",time.localtime(time.time()))\n",
    "starttime=time.time()\n",
    "\n",
    "train_result_summary_file='protein_train_leaderboard_evaluate_sklearn_'+str(timestamp)+'.csv'\n",
    "\n",
    "\n",
    "workpath=homepath+'/Human_AgonistAntagonist/GPCR_separatePROTEIN/Antagonist'\n",
    "\n",
    "trainname=substr[5]\n",
    "os.chdir(workpath)\n",
    "\n",
    "df_protein_train=pd.DataFrame()\n",
    "trainnum=0 \n",
    "################################### to all train separate ##########################################\n",
    "filenames=[]\n",
    "pp2skip=[]\n",
    "trainname1=trainname+'_'\n",
    "folderfiles=(sorted(next(walk(workpath))[2], reverse = True))\n",
    "for i, file in enumerate (folderfiles):\n",
    "    ppname=re.sub(trainname1,'',file)\n",
    "    if re.search('_train.csv', file):\n",
    "        ppname=re.sub(substr[1],'',ppname)\n",
    "        pp2skip.append(ppname)\n",
    "        continue\n",
    "    if re.search('_valid.csv', file):\n",
    "        ppname=re.sub(substr[2],'',ppname)\n",
    "        pp2skip.append(ppname)\n",
    "        continue\n",
    "    if re.search('_smalldataset.csv', file):\n",
    "        ppname=re.sub('_smalldataset.csv','',ppname)\n",
    "        pp2skip.append(ppname)\n",
    "        continue\n",
    "    if re.search(trainname, file):\n",
    "        filenames.append(file)\n",
    "        \n",
    "filenames=sorted(filenames)\n",
    "print (filenames,len(filenames))\n",
    "df_protein_train,trainnum = toTRAINfiles (workpath,trainnum,filenames,df_protein_train,substr,train_result_summary_file,AIlabel_problem_eval)\n",
    "\n",
    "print(time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n Total = ', (time.time()-starttime)/3600, ' hrs \\n' )\n",
    "\n",
    "\n",
    "os.chdir(workpath)\n",
    "df_protein_train.to_csv(train_result_summary_file,index=False,encoding='utf-8')\n",
    "\n",
    "\n",
    "\n",
    "print('\\n', time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '  \\n done all training separate  proteins \\n')\n",
    "\n",
    "\n",
    "###################################  alltrain concat ##########################################\n",
    "timestamp=time.strftime(\"%m%d\",time.localtime(time.time()))\n",
    "starttime=time.time()\n",
    "\n",
    "alltrainconcat_file = HUMANTRAINALLconcat(workpath,substr,trainname)\n",
    "\n",
    "filenames = [alltrainconcat_file]\n",
    "df_protein_train,trainnum = toTRAINfiles (workpath,trainnum,filenames,df_protein_train,substr,train_result_summary_file,AIlabel_problem_eval)\n",
    "\n",
    "\n",
    "os.chdir(workpath)\n",
    "df_protein_train.to_csv(train_result_summary_file,index=False,encoding='utf-8')\n",
    "\n",
    "\n",
    "##########################################\n",
    "\n",
    "if (time.time()-starttime)/3600 > 1 :\n",
    "    print(time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n Total = ', (time.time()-starttime)/3600, ' hrs \\n' )\n",
    "else:\n",
    "    print(time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n Total = ', (time.time()-starttime)/60, ' mins \\n' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbcc09b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### CODE: Main\n",
    "##### for separate protein AgonistAntagonist using Autogluon training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f41211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate protein AgonistAntagonist training\n",
    "\n",
    "timestamp=time.strftime(\"%Y%m%d%H%M\",time.localtime(time.time()))\n",
    "starttime=time.time()\n",
    "\n",
    "train_result_summary_file='protein_train_leaderboard_evaluate_sklearn_'+str(timestamp)+'.csv'\n",
    "\n",
    "workpath=homepath+'/Human_AgonistAntagonist/GPCR_separatePROTEIN/AgonistAntagonist'\n",
    "\n",
    "trainname=substr[3]\n",
    "os.chdir(workpath)\n",
    "\n",
    "df_protein_train=pd.DataFrame()\n",
    "trainnum=0 \n",
    "\n",
    "################################### to all train separate ##########################################\n",
    "filenames=[]\n",
    "pp2skip=[]\n",
    "trainname1=trainname+'_'\n",
    "folderfiles=(sorted(next(walk(workpath))[2], reverse = True))\n",
    "for i, file in enumerate (folderfiles):\n",
    "    ppname=re.sub(trainname1,'',file)\n",
    "    if re.search('_train.csv', file):\n",
    "        ppname=re.sub(substr[1],'',ppname)\n",
    "        pp2skip.append(ppname)\n",
    "        continue\n",
    "    if re.search('_valid.csv', file):\n",
    "        ppname=re.sub(substr[2],'',ppname)\n",
    "        pp2skip.append(ppname)\n",
    "        continue\n",
    "    if re.search('_smalldataset.csv', file):\n",
    "        ppname=re.sub('_smalldataset.csv','',ppname)\n",
    "        pp2skip.append(ppname)\n",
    "        continue\n",
    "    if re.search(trainname, file):\n",
    "        filenames.append(file)\n",
    "        \n",
    "filenames=sorted(filenames)\n",
    "print (filenames,len(filenames))\n",
    "df_protein_train,trainnum = toTRAINfiles (workpath,trainnum,filenames,df_protein_train,substr,train_result_summary_file,AIlabel_problem_eval)\n",
    "\n",
    "print(time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n Total = ', (time.time()-starttime)/3600, ' hrs \\n' )\n",
    "\n",
    "\n",
    "os.chdir(workpath)\n",
    "df_protein_train.to_csv(train_result_summary_file,index=False,encoding='utf-8')\n",
    "\n",
    "\n",
    "\n",
    "print('\\n', time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '  \\n done all training separate  proteins \\n')\n",
    "\n",
    "\n",
    "###################################  alltrain concat ##########################################\n",
    "timestamp=time.strftime(\"%m%d\",time.localtime(time.time()))\n",
    "starttime=time.time()\n",
    "\n",
    "alltrainconcat_file = HUMANTRAINALLconcat(workpath,substr,trainname)\n",
    "\n",
    "filenames = [alltrainconcat_file]\n",
    "df_protein_train,trainnum = toTRAINfiles (workpath,trainnum,filenames,df_protein_train,substr,train_result_summary_file,AIlabel_problem_eval)\n",
    "\n",
    "\n",
    "os.chdir(workpath)\n",
    "df_protein_train.to_csv(train_result_summary_file,index=False,encoding='utf-8')\n",
    "\n",
    "\n",
    "##########################################\n",
    "\n",
    "if (time.time()-starttime)/3600 > 1 :\n",
    "    print(time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n Total = ', (time.time()-starttime)/3600, ' hrs \\n' )\n",
    "else:\n",
    "    print(time.strftime(\"%Y/%m/%d %H:%M:%S\",time.localtime(time.time())), '\\n Total = ', (time.time()-starttime)/60, ' mins \\n' )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
